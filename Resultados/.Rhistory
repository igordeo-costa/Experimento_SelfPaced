https://raw.githubusercontent.com/igordeo-costa/Experimento_EscolhaForcada/main/Estudo%20normativo/chunk_includes/Distratores.csv
# Carregando a tabela com a resposta esperada por cada frase direto do GitHub
expected_answers <- read.csv("/home/dados/Acadêmicos/Doutorado/EXPERIMENTOS2021/SelfPacedReading/Distratoras.csv")
# Carregando a tabela com a resposta esperada por cada frase direto do GitHub
expected_answers <- read.csv("/home/dados/Acadêmicos/Doutorado/EXPERIMENTOS_2021/SelfPacedReading/Distratoras.csv")
View(expected_answers)
expected_answers %>%
select(c(posicao, resposta, frase))
x %>%
filter(Label == "distrat")
View(dist)
expected_answers <- edit(expected_answers)
expected_answers %>%
select(c(lista, resposta, frase)) %>%
inner_join(dist, by = c("frase", "lista"))
expected_answers %>%
select(c(lista, resposta, frase)) %>%
inner_join(dist, by = c("frase", "lista")) %>%
filter(Parametro == "Choice") %>%
mutate(Escolha = str_replace_all(Position, c("uma" = "um"))) %>%
filter(Escolha %in% c("Apenas um", "Mais de um"))
# Mesclando as duas tabelas e filtrando apenas respostas à escolha forçada
dist <- expected_answers %>%
select(c(lista, resposta, frase)) %>%
inner_join(dist, by = c("frase", "lista")) %>%
filter(Parametro == "Choice") %>%
mutate(Escolha = str_replace_all(Position, c("uma" = "um"))) %>%
filter(Escolha %in% c("Apenas um", "Mais de um"))
# Carregando a tabela com a resposta esperada por cada frase direto do GitHub
expected_answers <- read.csv("/home/dados/Acadêmicos/Doutorado/EXPERIMENTOS_2021/SelfPacedReading/Distratoras.csv")
View(expected_answers)
View(dist)
# Análise por sujeitos
dist$Participante <- as.factor(dist$Participante)
# Análise das distratoras por frase
cores <- brewer.pal(name = "Set1", n = 3)
View(dist)
dist %>%
group_by(Position, Participante, Escolha) %>%
tally()
View(dist)
dist %>%
group_by(Position, Participante, Escolha) %>%
tally() %>%
mutate(porc = n/sum(n, na.rm = T)) %>%
mutate(SE=sqrt((porc*(1-porc))/n)) %>% # Calcula o erro padrão (Standad Error ou SE) da proporção
mutate(SE_inf=porc-SE) %>%
mutate(SE_sup=porc+SE) %>%
mutate(SE_inf=if_else(SE_inf<0, 0, SE_inf)) %>%
filter(Escolha == "Apenas um")
dist %>%
group_by(Position, Participante, Escolha) %>%
tally() %>%
mutate(porc = n/sum(n, na.rm = T)) %>%
mutate(SE=sqrt((porc*(1-porc))/n)) %>% # Calcula o erro padrão (Standad Error ou SE) da proporção
mutate(SE_inf=porc-SE) %>%
mutate(SE_sup=porc+SE) %>%
mutate(SE_inf=if_else(SE_inf<0, 0, SE_inf)) %>%
filter(Escolha == "Apenas um") %>% # Ou "Mais de um" aqui... Tanto faz...
#filter(!UniqueReceptionTime %in% c("1632311528", "1631919148")) %>%
ggplot(aes(x = Participante, y = porc, color = Position)) +
geom_hline(aes(yintercept = 0.5), linetype = "dashed", color = "grey60") +
geom_errorbar(aes(ymin = SE_inf, ymax = SE_sup), width = 0.3, size = 0.7, color = "grey") +
geom_point(size = 2, stroke = 1, fill = "white", shape = 21) +
coord_flip() +
theme_classic() +
scale_y_continuous(labels = scales::label_percent(accuracy = 1L)) +
scale_color_manual(values = cores, name = "Resposta Esperada:",
labels = c("Mais de um", "Apenas um")) +
labs(x = "", y = "") +
theme(text = element_text(size=14),
legend.position = "top",
legend.text = element_text(size=14),
axis.text.y = element_blank(),
axis.ticks.y = element_blank())
# Função para limpeza dos dados
read.pcibex <- function(filepath, auto.colnames=TRUE, fun.col=function(col,cols){cols[cols==col]<-paste(col,"Ibex",sep=".");return(cols)}) {
n.cols <- max(count.fields(filepath,sep=",",quote=NULL),na.rm=TRUE)
if (auto.colnames){
cols <- c()
con <- file(filepath, "r")
while ( TRUE ) {
line <- readLines(con, n = 1, warn=FALSE)
if ( length(line) == 0) {
break
}
m <- regmatches(line,regexec("^# (\\d+)\\. (.+)\\.$",line))[[1]]
if (length(m) == 3) {
index <- as.numeric(m[2])
value <- m[3]
if (is.function(fun.col)){
cols <- fun.col(value,cols)
}
cols[index] <- value
if (index == n.cols){
break
}
}
}
close(con)
return(read.csv(filepath, comment.char="#", header=FALSE, col.names=cols))
}
else{
return(read.csv(filepath, comment.char="#", header=FALSE, col.names=seq(1:n.cols)))
}
}
# Pacotes necessários
require(dplyr)
require(tidyr)
require(stringr)
require(ggplot2)
require(scales)
require(forcats)
require(RColorBrewer)
require(gridExtra)
require(lme4)
dados <- read.pcibex("~/Downloads/results_112suj.csv")
# Número de participantes:
length(unique(dados$Results.reception.time))
x <- dados %>%
select(-c("Newline.", "Sentence..or.sentence.MD5.", "Inner.element.number",
"Latin.Square.Group", "Comments", "Controller.name"))
colnames(x) <- c("Participante", "ID_Partic", "Ordem", "Label",
"ElemType", "ElemName", "Parametro",
"Position", "EventTime", "ID", "quant",
"item", "frase", "lista", "idade",
"gender", "escol", "nativo", "RT")
#-------------------------------------------------------------------------------
# Analisando os critérios de exclusão
#-------------------------------------------------------------------------------
# Falante nativo
x %>%
filter(nativo %in% c("Sim", "Não")) %>%
group_by(Participante, nativo) %>%
tally() %>%
group_by(Participante, nativo) %>%
summarise(n = n/n) %>%
group_by(nativo) %>%
tally()
# Exclusão de não nativos: 1 participante excluído
clean_data <- x %>%
filter(nativo == "Sim")
# Dados de escolaridade (exclusão)
clean_data %>%
group_by(Participante, escol) %>%
tally() %>%
group_by(Participante, escol) %>%
summarise(n = n/n) %>%
group_by(escol) %>%
tally()
# Exclusão dos participantes que não atenderam ao critério de escolaridade: 1 participante excluído
clean_data <- clean_data %>%
filter(!escol %in% c("Ensino Médio incompleto"))
# Análise das declarações de gênero
clean_data %>%
group_by(Participante, gender) %>%
tally() %>%
group_by(Participante, gender) %>%
summarise(n = n/n) %>%
group_by(gender) %>%
tally()
#------------------------------------------------------
# Análise da escolha forçada e participantes por lista
#------------------------------------------------------
escolha <- clean_data %>%
filter(Label == "experiment") %>%
filter(Parametro == "Choice")
# Total de participantes por lista
escolha %>%
group_by(lista) %>%
tally() %>%
mutate(partic_por_lista = n/12) # frases vistas por participante = 12
choice_data <- escolha %>%
mutate(Position = str_replace_all(Position, c("%09" = ""))) %>%
mutate(Position = str_replace_all(Position, c("uma" = "um")))
# Total de respostas à escolha forçada perdidas
choice_data %>%
mutate_if(is.character, as.factor) %>%
mutate_if(is.integer, as.factor) %>%
group_by(quant) %>%
tally(is.na(Position))
dist <- clean_data %>%
filter(Label == "distrat")
# Carregando a tabela com a resposta esperada por cada frase direto do GitHub
expected_answers <- read.csv("/home/dados/Acadêmicos/Doutorado/EXPERIMENTOS_2021/SelfPacedReading/Distratoras.csv")
View(dist)
View(expected_answers)
View(dist)
expected_answers <- edit(expected_answers)
expected_answers %>%
select(c(lista, resposta, frase))
expected_answers %>%
select(c(lista, resposta, frase)) %>%
inner_join(dist, by = c("frase", "lista")) %>%
filter(Parametro == "Choice")
# Mesclando as duas tabelas e filtrando apenas respostas à escolha forçada
dist <- expected_answers %>%
select(c(lista, resposta, frase)) %>%
inner_join(dist, by = c("frase", "lista")) %>%
filter(Parametro == "Choice") %>%
mutate(Escolha = str_replace_all(Position, c("uma" = "um"))) %>%
filter(Escolha %in% c("Apenas um", "Mais de um"))
# Análise por sujeitos
dist$Participante <- as.factor(dist$Participante)
View(dist)
dist %>%
group_by(resposta, Participante, Position) %>%
tally()
# Análise por sujeitos
dist$Participante <- as.factor(dist$Participante)
# Análise das distratoras por frase
cores <- brewer.pal(name = "Set1", n = 3)
dist %>%
group_by(resposta, Participante, Position)
dist %>%
group_by(resposta, Participante, Position) %>%
tally() %>%
mutate(porc = n/sum(n, na.rm = T)) %>%
mutate(SE=sqrt((porc*(1-porc))/n)) %>% # Calcula o erro padrão (Standad Error ou SE) da proporção
mutate(SE_inf=porc-SE) %>%
mutate(SE_sup=porc+SE) %>%
mutate(SE_inf=if_else(SE_inf<0, 0, SE_inf)) %>%
filter(Escolha == "Apenas um")
dist %>%
group_by(resposta, Participante, Position) %>%
tally() %>%
mutate(porc = n/sum(n, na.rm = T)) %>%
mutate(SE=sqrt((porc*(1-porc))/n)) %>% # Calcula o erro padrão (Standad Error ou SE) da proporção
mutate(SE_inf=porc-SE) %>%
mutate(SE_sup=porc+SE) %>%
mutate(SE_inf=if_else(SE_inf<0, 0, SE_inf)) %>%
filter(Position == "Apenas um")
dist %>%
group_by(resposta, Participante, Position) %>%
tally() %>%
mutate(porc = n/sum(n, na.rm = T)) %>%
mutate(SE=sqrt((porc*(1-porc))/n)) %>% # Calcula o erro padrão (Standad Error ou SE) da proporção
mutate(SE_inf=porc-SE) %>%
mutate(SE_sup=porc+SE) %>%
mutate(SE_inf=if_else(SE_inf<0, 0, SE_inf)) %>%
filter(Position == "Apenas um") %>% # Ou "Mais de um" aqui... Tanto faz...
#filter(!UniqueReceptionTime %in% c("1632311528", "1631919148")) %>%
ggplot(aes(x = Participante, y = porc, color = resposta)) +
geom_hline(aes(yintercept = 0.5), linetype = "dashed", color = "grey60") +
geom_errorbar(aes(ymin = SE_inf, ymax = SE_sup), width = 0.3, size = 0.7, color = "grey") +
geom_point(size = 2, stroke = 1, fill = "white", shape = 21) +
coord_flip() +
theme_classic() +
scale_y_continuous(labels = scales::label_percent(accuracy = 1L)) +
scale_color_manual(values = cores, name = "Resposta Esperada:",
labels = c("Mais de um", "Apenas um")) +
labs(x = "", y = "") +
theme(text = element_text(size=14),
legend.position = "top",
legend.text = element_text(size=14),
axis.text.y = element_blank(),
axis.ticks.y = element_blank())
dist %>%
group_by(resposta, Participante, Position) %>%
tally() %>%
mutate(porc = n/sum(n, na.rm = T)) %>%
mutate(SE=sqrt((porc*(1-porc))/n)) %>% # Calcula o erro padrão (Standad Error ou SE) da proporção
mutate(SE_inf=porc-SE) %>%
mutate(SE_sup=porc+SE) %>%
mutate(SE_inf=if_else(SE_inf<0, 0, SE_inf)) %>%
filter(Position == "Mais de um") %>% # Ou "Mais de um" aqui... Tanto faz...
#filter(!UniqueReceptionTime %in% c("1632311528", "1631919148")) %>%
ggplot(aes(x = Participante, y = porc, color = resposta)) +
geom_hline(aes(yintercept = 0.5), linetype = "dashed", color = "grey60") +
geom_errorbar(aes(ymin = SE_inf, ymax = SE_sup), width = 0.3, size = 0.7, color = "grey") +
geom_point(size = 2, stroke = 1, fill = "white", shape = 21) +
coord_flip() +
theme_classic() +
scale_y_continuous(labels = scales::label_percent(accuracy = 1L)) +
scale_color_manual(values = cores, name = "Resposta Esperada:",
labels = c("Mais de um", "Apenas um")) +
labs(x = "", y = "") +
theme(text = element_text(size=14),
legend.position = "top",
legend.text = element_text(size=14),
axis.text.y = element_blank(),
axis.ticks.y = element_blank())
dist %>%
group_by(resposta, Participante, Position) %>%
tally() %>%
mutate(porc = n/sum(n, na.rm = T)) %>%
mutate(SE=sqrt((porc*(1-porc))/n)) %>% # Calcula o erro padrão (Standad Error ou SE) da proporção
mutate(SE_inf=porc-SE) %>%
mutate(SE_sup=porc+SE) %>%
mutate(SE_inf=if_else(SE_inf<0, 0, SE_inf)) %>%
filter(Position == "Apenas um") %>% # Ou "Mais de um" aqui... Tanto faz...
#filter(!UniqueReceptionTime %in% c("1632311528", "1631919148")) %>%
ggplot(aes(x = Participante, y = porc, color = resposta)) +
geom_hline(aes(yintercept = 0.5), linetype = "dashed", color = "grey60") +
geom_errorbar(aes(ymin = SE_inf, ymax = SE_sup), width = 0.3, size = 0.7, color = "grey") +
geom_point(size = 2, stroke = 1, fill = "white", shape = 21) +
coord_flip() +
theme_classic() +
scale_y_continuous(labels = scales::label_percent(accuracy = 1L)) +
scale_color_manual(values = cores, name = "Resposta Esperada:",
labels = c("Mais de um", "Apenas um")) +
labs(x = "", y = "") +
theme(text = element_text(size=14),
legend.position = "top",
legend.text = element_text(size=14),
axis.text.y = element_blank(),
axis.ticks.y = element_blank())
dist %>%
group_by(resposta, Participante, Position) %>%
tally() %>%
mutate(porc = n/sum(n, na.rm = T)) %>%
mutate(SE=sqrt((porc*(1-porc))/n)) %>% # Calcula o erro padrão (Standad Error ou SE) da proporção
mutate(SE_inf=porc-SE) %>%
mutate(SE_sup=porc+SE) %>%
mutate(SE_inf=if_else(SE_inf<0, 0, SE_inf)) %>%
filter(Position == "Apenas um") %>% # Ou "Mais de um" aqui... Tanto faz...
#filter(!UniqueReceptionTime %in% c("1632311528", "1631919148")) %>%
ggplot(aes(x = Participante, y = porc, color = Position)) +
geom_hline(aes(yintercept = 0.5), linetype = "dashed", color = "grey60") +
geom_errorbar(aes(ymin = SE_inf, ymax = SE_sup), width = 0.3, size = 0.7, color = "grey") +
geom_point(size = 2, stroke = 1, fill = "white", shape = 21) +
coord_flip() +
theme_classic() +
scale_y_continuous(labels = scales::label_percent(accuracy = 1L)) +
scale_color_manual(values = cores, name = "Resposta Esperada:",
labels = c("Mais de um", "Apenas um")) +
labs(x = "", y = "") +
theme(text = element_text(size=14),
legend.position = "top",
legend.text = element_text(size=14),
axis.text.y = element_blank(),
axis.ticks.y = element_blank())
dist %>%
group_by(resposta, Participante, Position) %>%
tally() %>%
mutate(porc = n/sum(n, na.rm = T)) %>%
mutate(SE=sqrt((porc*(1-porc))/n)) %>% # Calcula o erro padrão (Standad Error ou SE) da proporção
mutate(SE_inf=porc-SE) %>%
mutate(SE_sup=porc+SE) %>%
mutate(SE_inf=if_else(SE_inf<0, 0, SE_inf)) %>%
filter(Position == "Apenas um") %>% # Ou "Mais de um" aqui... Tanto faz...
#filter(!UniqueReceptionTime %in% c("1632311528", "1631919148")) %>%
ggplot(aes(x = Participante, y = porc, color = resposta)) +
geom_hline(aes(yintercept = 0.5), linetype = "dashed", color = "grey60") +
geom_errorbar(aes(ymin = SE_inf, ymax = SE_sup), width = 0.3, size = 0.7, color = "grey") +
geom_point(size = 2, stroke = 1, fill = "white", shape = 21) +
coord_flip() +
theme_classic() +
scale_y_continuous(labels = scales::label_percent(accuracy = 1L)) +
scale_color_manual(values = cores, name = "Resposta Esperada:",
labels = c("Mais de um", "Apenas um")) +
labs(x = "", y = "") +
theme(text = element_text(size=14),
legend.position = "top",
legend.text = element_text(size=14),
axis.text.y = element_blank(),
axis.ticks.y = element_blank())
dist %>%
group_by(resposta, Participante, Position) %>%
tally() %>%
mutate(porc = n/sum(n, na.rm = T))
# Mesclando as duas tabelas e filtrando apenas respostas à escolha forçada
dist <- expected_answers %>%
select(c(lista, resposta, frase)) %>%
inner_join(dist, by = c("frase", "lista")) %>%
filter(Parametro == "Choice") %>%
mutate(Escolha = str_replace_all(Position, c("uma" = "um"))) %>%
filter(Escolha %in% c("Apenas um", "Mais de um"))
# Análise por sujeitos
dist$Participante <- as.factor(dist$Participante)
# Análise das distratoras por frase
cores <- brewer.pal(name = "Set1", n = 3)
dist %>%
group_by(resposta, Participante, Position) %>%
tally() %>%
mutate(porc = n/sum(n, na.rm = T))
# Mesclando as duas tabelas e filtrando apenas respostas à escolha forçada
dist <- expected_answers %>%
select(c(lista, resposta, frase)) %>%
inner_join(dist, by = c("frase", "lista")) %>%
filter(Parametro == "Choice") %>%
mutate(resposta = str_replace_all(Position, c("uma" = "um"))) %>%
filter(resposta %in% c("Apenas um", "Mais de um"))
# Análise por sujeitos
dist$Participante <- as.factor(dist$Participante)
# Análise das distratoras por frase
cores <- brewer.pal(name = "Set1", n = 3)
dist %>%
group_by(resposta, Participante, Position) %>%
tally() %>%
mutate(porc = n/sum(n, na.rm = T))
dist %>%
group_by(resposta, Participante, Position) %>%
tally() %>%
mutate(porc = n/sum(n, na.rm = T)) %>%
mutate(SE=sqrt((porc*(1-porc))/n))
# Mesclando as duas tabelas e filtrando apenas respostas à escolha forçada
dist <- expected_answers %>%
select(c(lista, resposta, frase)) %>%
inner_join(dist, by = c("frase", "lista")) %>%
filter(Parametro == "Choice") %>%
mutate(Position = str_replace_all(Position, c("uma" = "um"))) %>%
filter(Position %in% c("Apenas um", "Mais de um"))
# Análise por sujeitos
dist$Participante <- as.factor(dist$Participante)
# Análise das distratoras por frase
cores <- brewer.pal(name = "Set1", n = 3)
dist %>%
group_by(resposta, Participante, Position) %>%
tally() %>%
mutate(porc = n/sum(n, na.rm = T))
expected_answers %>%
select(c(lista, resposta, frase)) %>%
inner_join(dist, by = c("frase", "lista")) %>%
filter(Parametro == "Choice")
# Função para limpeza dos dados
read.pcibex <- function(filepath, auto.colnames=TRUE, fun.col=function(col,cols){cols[cols==col]<-paste(col,"Ibex",sep=".");return(cols)}) {
n.cols <- max(count.fields(filepath,sep=",",quote=NULL),na.rm=TRUE)
if (auto.colnames){
cols <- c()
con <- file(filepath, "r")
while ( TRUE ) {
line <- readLines(con, n = 1, warn=FALSE)
if ( length(line) == 0) {
break
}
m <- regmatches(line,regexec("^# (\\d+)\\. (.+)\\.$",line))[[1]]
if (length(m) == 3) {
index <- as.numeric(m[2])
value <- m[3]
if (is.function(fun.col)){
cols <- fun.col(value,cols)
}
cols[index] <- value
if (index == n.cols){
break
}
}
}
close(con)
return(read.csv(filepath, comment.char="#", header=FALSE, col.names=cols))
}
else{
return(read.csv(filepath, comment.char="#", header=FALSE, col.names=seq(1:n.cols)))
}
}
# Pacotes necessários
require(dplyr)
require(tidyr)
require(stringr)
require(ggplot2)
require(scales)
require(forcats)
require(RColorBrewer)
require(gridExtra)
require(lme4)
dados <- read.pcibex("~/Downloads/results_112suj.csv")
# Número de participantes:
length(unique(dados$Results.reception.time))
x <- dados %>%
select(-c("Newline.", "Sentence..or.sentence.MD5.", "Inner.element.number",
"Latin.Square.Group", "Comments", "Controller.name"))
colnames(x) <- c("Participante", "ID_Partic", "Ordem", "Label",
"ElemType", "ElemName", "Parametro",
"Position", "EventTime", "ID", "quant",
"item", "frase", "lista", "idade",
"gender", "escol", "nativo", "RT")
#-------------------------------------------------------------------------------
# Analisando os critérios de exclusão
#-------------------------------------------------------------------------------
# Falante nativo
x %>%
filter(nativo %in% c("Sim", "Não")) %>%
group_by(Participante, nativo) %>%
tally() %>%
group_by(Participante, nativo) %>%
summarise(n = n/n) %>%
group_by(nativo) %>%
tally()
# Exclusão de não nativos
clean_data <- x %>%
filter(nativo == "Sim") %>% # 1 participante excluído
filter(!Participante %in% c("1638920395", "1638474825")) # 2 participantes excluídos por inconsistência nas distratoras (ver abaixo)
# Dados de escolaridade (exclusão)
clean_data %>%
group_by(Participante, escol) %>%
tally() %>%
group_by(Participante, escol) %>%
summarise(n = n/n) %>%
group_by(escol) %>%
tally()
# Exclusão dos participantes que não atenderam ao critério de escolaridade: 1 participante excluído
clean_data <- clean_data %>%
filter(!escol %in% c("Ensino Médio incompleto"))
# Análise das declarações de gênero
clean_data %>%
group_by(Participante, gender) %>%
tally() %>%
group_by(Participante, gender) %>%
summarise(n = n/n) %>%
group_by(gender) %>%
tally()
# Idade média dos participantes
clean_data %>%
group_by(Participante) %>%
summarise(idade = unique(idade)) %>%
ungroup() %>%
summarise(idadeMedia = mean(idade),
idadeMin = min(idade),
idadeMax = max(idade))
setwd("/home/dados/Acadêmicos/Doutorado/EXPERIMENTOS_2021/SelfPacedReading/PastaGithub/Resultados/")
write.csv(clean_data, "Resultados_limpos.csv")
